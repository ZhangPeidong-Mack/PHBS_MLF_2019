{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import random\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('../data/data_part1.csv')\n",
    "df2 = pd.read_csv('../data/data_part2.csv')\n",
    "stockprice = pd.concat([df1,df2], axis=0)\n",
    "stockprice.drop(columns=['Unnamed: 0'],inplace=True)\n",
    "stockprice.sort_values(by=['time'],ascending=True,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select tradedates & Stock ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##select tradedates\n",
    "tradedate = stockprice['time']\n",
    "tradedate = tradedate.drop_duplicates()\n",
    "tradedate = list(tradedate)\n",
    "\n",
    "##select stockID\n",
    "stockid = stockprice['code']\n",
    "stockid = stockid.drop_duplicates()\n",
    "stockid = list(stockid)\n",
    "\n",
    "##sort data according to stockid and time\n",
    "stockprice.sort_values(by=['code','time'],ascending=True,inplace=True)\n",
    "stockprice = stockprice.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop stocks which were delisted from market during 2017-2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = stockprice.loc[np.isnan(stockprice['close']),'code']\n",
    "ss = list(ss.drop_duplicates())\n",
    "\n",
    "filtered = []\n",
    "for i in range(0,len(stockid)):\n",
    "    if stockid[i] not in ss:\n",
    "        filtered.append(stockid[i])\n",
    "\n",
    "df = stockprice.loc[stockprice['code'].isin(filtered)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import package 'talib' to compute several features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import talib\n",
    "df['MOM'] = talib.MOM(df.loc[:, 'close'],timeperiod=5)\n",
    "\n",
    "df['RSI']=talib.RSI(df.close.values, timeperiod=6)\n",
    "df['EMA6'] = talib.EMA(df.close.values, timeperiod=6)  \n",
    "df['EMA12'] = talib.EMA(df.close.values, timeperiod=12)   \n",
    "df['MACD'],df['MACDsignal'],df['MACDhist'] = talib.MACD(df.close.values,\n",
    "                            fastperiod=6, slowperiod=12, signalperiod=9)\n",
    "df['atr'] = talib.ATR(df.high.values,df.low.values,df.close.values, timeperiod=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop nan data due to features computing & save modified data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "remaindate = tradedate[19:]\n",
    "ddf = df.loc[df['time'].isin(remaindate)]\n",
    "ddf = ddf.reset_index(drop=True)\n",
    "\n",
    "#save modified data\n",
    "ddf.to_csv('modifieddata.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split 80% data in the front into training set and last 20% into test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "remaindate = ddf['time']\n",
    "remaindate = remaindate.drop_duplicates()\n",
    "remaindate = list(remaindate)\n",
    "\n",
    "traindate = remaindate[:570]\n",
    "testdate = remaindate[570:710]\n",
    "\n",
    "traindata = ddf.loc[ddf['time'].isin(traindate)]\n",
    "testdata = ddf.loc[ddf['time'].isin(testdate)]\n",
    "##save training data and test data\n",
    "traindata.to_csv('traindata.csv')\n",
    "testdata.to_csv('testdata.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement PCA on training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.48619757 0.3416973  0.09348087]\n"
     ]
    }
   ],
   "source": [
    "##train set\n",
    "trMOM = traindata.MOM.values\n",
    "trRSI = traindata.RSI.values\n",
    "trEMA6 = traindata.EMA6.values\n",
    "trEMA12 = traindata.EMA12.values\n",
    "trMACD = traindata.MACD.values\n",
    "tratr = traindata.atr.values\n",
    "\n",
    "ss = pd.DataFrame({'MOM':trMOM,'RSI':trRSI,'EMA6':trEMA6,'EMA12':trEMA12,'MACD':trMACD,'ATR':tratr})\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "##Standardlization\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(ss)\n",
    "trans_ss = scaler.transform(ss)\n",
    "\n",
    "##PCA\n",
    "pca = PCA(n_components=3)\n",
    "newss = pca.fit_transform(trans_ss)\n",
    "print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement PCA on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "##test set\n",
    "teMOM = testdata.MOM.values\n",
    "teRSI = testdata.RSI.values\n",
    "teEMA6 = testdata.EMA6.values\n",
    "teEMA12 = testdata.EMA12.values\n",
    "teMACD = testdata.MACD.values\n",
    "teatr = testdata.atr.values\n",
    "\n",
    "xx = pd.DataFrame({'MOM':teMOM,'RSI':teRSI,'EMA6':teEMA6,'EMA12':teEMA12,'MACD':teMACD,'ATR':teatr})\n",
    "##标准化&主成分\n",
    "trans_xx = scaler.transform(xx)\n",
    "newxx = pca.transform(trans_xx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label 1 for up trend and -1 for down trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata = traindata.reset_index(drop=True)   \n",
    "Ytrain = []\n",
    "for i in range(0,len(traindata)):\n",
    "    if i%10 == 9:\n",
    "        if traindata.loc[i,'close'] > traindata.loc[i-4,'close']:\n",
    "            Ytrain.append(1)\n",
    "        else:\n",
    "            Ytrain.append(-1)   \n",
    "\n",
    "\n",
    "testdata = testdata.reset_index(drop=True)\n",
    "Ytest = []\n",
    "for i in range(0,len(testdata)):\n",
    "    if i%10 == 9:\n",
    "        if testdata.loc[i,'close'] > testdata.loc[i-4,'close']:\n",
    "            Ytest.append(1)\n",
    "        else:\n",
    "            Ytest.append(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform X data in training set and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = []\n",
    "for i in range(0,len(newss)):\n",
    "    if i%10 == 4:\n",
    "       temp = []\n",
    "       for j in range(4,-1,-1): \n",
    "           temp.append(newss[i-j,0])\n",
    "           temp.append(newss[i-j,1])\n",
    "           temp.append(newss[i-j,2])\n",
    "       Xtrain.append(temp)\n",
    "    \n",
    "Xtest = []\n",
    "for i in range(0,len(newxx)):\n",
    "    if i%10 == 4:\n",
    "       temp = []\n",
    "       for j in range(4,-1,-1): \n",
    "           temp.append(newxx[i-j,0])\n",
    "           temp.append(newxx[i-j,1])\n",
    "           temp.append(newxx[i-j,2])\n",
    "       Xtest.append(temp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
